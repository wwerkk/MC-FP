{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"audio-data/drumloop2.mp3\"\n",
    "name = \"drumloop2\"\n",
    "\n",
    "# segmentation\n",
    "block_length = 1 # number of frames in a stream block\n",
    "BPM = 120\n",
    "beat = 1 / 8 # metered divisions\n",
    "hop_beats = 1 / 8 # hop length in beats\n",
    "## alternatively, you can specify frame length and hop length in seconds\n",
    "# frame_length_s = 0.1\n",
    "# hop_length_s = 0.02\n",
    "## or in samples\n",
    "# frame_length = 4096\n",
    "# hop_length = 1024\n",
    "\n",
    "# clustering\n",
    "n_classes = 4\n",
    "maxlen = 8\n",
    "# model architecture and training\n",
    "step = 1 # step size for sliding window\n",
    "hidden_units = 24 # number of hidden units in GRU layer\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "validation_split = 0.2\n",
    "patience = 15 # number of epochs to wait before early stopping\n",
    "\n",
    "# utility\n",
    "verbose = 1 # print additional information\n",
    "directory = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np, matplotlib.pyplot as plt, librosa\n",
    "import librosa.display\n",
    "# import IPython.display\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "import json\n",
    "from numpyencoder import NumpyEncoder\n",
    "from sklearn import preprocessing, cluster\n",
    "from streamer import Streamer\n",
    "import scipy\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "\n",
    "if BPM is None and beat is not None or BPM is not None and beat is None:\n",
    "    print(\"Please specify both BPM and beat if you are using metered divisions.\")\n",
    "    exit()\n",
    "frame_length_s = (4 * beat * 60 / BPM) if BPM is not None else args.frame_length_s\n",
    "hop_length_s = (4 * hop_beats * 60 / BPM) if BPM is not None else args.hop_length_s\n",
    "sr = librosa.get_samplerate(audio_path)\n",
    "frame_length = math.ceil(frame_length_s * sr) if frame_length_s is not None else args.frame_length\n",
    "hop_length = math.ceil(hop_length_s * sr) if hop_length_s is not None else args.hop_length\n",
    "stream = Streamer(audio_path, block_length, frame_length, hop_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to extract features from audio block\n",
    "def extract_features(y, sr):\n",
    "    zcr = [librosa.zero_crossings(y).sum()]\n",
    "    energy = [scipy.linalg.norm(y)]\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_bandwith = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    m_centroid = np.median(spectral_centroid, axis=1)\n",
    "    m_bandwith = np.median(spectral_bandwith, axis=1)\n",
    "    m_flatness = np.median(spectral_flatness, axis=1)\n",
    "    m_rolloff = np.median(spectral_rolloff, axis=1)\n",
    "    if y.size >= 2048:  \n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, center=False) # mfccs\n",
    "    else:\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=len(y), hop_length=len(y), center=False)\n",
    "    \n",
    "    m_mfccs = np.median(mfccs[1:], axis=1)\n",
    "    if m_mfccs.size == 0:\n",
    "        print(\"Empty frame!\")\n",
    "        return None\n",
    "    else:        \n",
    "        features = np.concatenate((zcr, energy, m_centroid, m_bandwith, m_flatness, m_rolloff, m_mfccs))\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # helper function to extract features from audio block\n",
    "# def extract_features(y, sr):\n",
    "#     # zcr = [librosa.zero_crossings(y).sum()]\n",
    "#     # energy = [scipy.linalg.norm(y)]  \n",
    "#     # features = np.concatenate((zcr, energy))\n",
    "#     if y.size >= 2048:  \n",
    "#         mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, center=False) # mfccs\n",
    "#     else:\n",
    "#         mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=len(y), hop_length=len(y), center=False)\n",
    "    \n",
    "#     m_mfccs = np.median(mfccs, axis=1)\n",
    "#     features = m_mfccs\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio length: 192.0s, 9216000 samples\n",
      "Sample rate: 48000 Hz\n",
      "Frame length: 0.25s,  12000 samples\n",
      "Hop length: 0.25s, 12000 samples\n",
      "Block length: 1 frame(s)\n",
      "Number of blocks: 768\n",
      "(768, 18)\n",
      "(768, 18)\n",
      "[-1.20912548 -0.70367295 -1.40830221 -1.75501487 -0.78510325 -1.52416177\n",
      " -1.08109916 -0.93250422 -1.67116297 -1.02150858 -1.26397981 -1.16350423\n",
      " -1.55860403 -1.46469779 -1.67957673 -1.36224387 -1.20178167 -1.46839212]\n",
      "[1.6756064  1.72797858 1.33090008 0.8084763  2.00051128 1.01289278\n",
      " 1.0638992  1.67663802 0.904818   1.6500955  1.20020867 1.29995843\n",
      " 1.2125082  1.46927717 1.4785515  1.46298534 1.79257932 1.33017799]\n",
      "[-1.12692823  1.72750412 -1.40830221 -1.70239536 -0.78509724 -1.52416177\n",
      "  0.96740243  1.66021017  0.82655345  1.62735598  0.88659916  1.22015238\n",
      "  0.70937408  1.32903366  0.54753142  1.35847161 -0.20515291  1.27720662]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Audio length: {stream.length}s, {stream.n_samples} samples\")\n",
    "print(f\"Sample rate: {sr} Hz\")\n",
    "print(f\"Frame length: {frame_length_s}s,  {frame_length} samples\")\n",
    "print(f\"Hop length: {hop_length_s}s, {hop_length} samples\")\n",
    "print(f\"Block length: {block_length} frame(s)\")\n",
    "print(f\"Number of blocks: {len(stream)}\")\n",
    "\n",
    "# extract features from each block in audio stream\n",
    "features = np.array([extract_features(block, sr) for block in stream.new()])\n",
    "# features_scaled = features\n",
    "features_scaled = preprocessing.scale(features, axis=0) # should it be axis 0 then not 1??\n",
    "if verbose:\n",
    "    # print(features[0])\n",
    "    print(features.shape)\n",
    "    print(features_scaled.shape)\n",
    "    print(features_scaled.min(axis=0))\n",
    "    print(features_scaled.max(axis=0))\n",
    "    print(features_scaled[0]) # type: ignore\n",
    "if verbose:\n",
    "    plt.scatter(features[:,0], features[:,1], ) # type: ignore\n",
    "    # plt.xlabel('MFCC0 (scaled)')\n",
    "    # plt.ylabel('MFCC1 Centroid (scaled)')   \n",
    "    plt.show()\n",
    "    plt.scatter(features_scaled[:,0], features_scaled[:,1], ) # type: ignore\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labelled frames: 768\n",
      "n_labels: 4 (sanity check)\n",
      "384\n",
      "24000 36000\n",
      "(760, 8, 4)\n",
      "(760, 4)\n"
     ]
    }
   ],
   "source": [
    "# cluster features\n",
    "# frames = [frame for frame in frames if frame.size != 0] # remove empty\n",
    "c_model = cluster.KMeans(n_clusters=n_classes, n_init='auto')\n",
    "labels = c_model.fit_predict(features_scaled)\n",
    "\n",
    "n_labels = len(np.unique(labels))\n",
    "labels = labels.tolist()\n",
    "if verbose:\n",
    "    print(f\"Total labelled frames: {len(labels)}\")\n",
    "    print(f\"n_labels: {n_labels} (sanity check)\")\n",
    "\n",
    "frames = []\n",
    "for i, block in enumerate(stream.new()):\n",
    "    frames.append([i * hop_length, i * hop_length + frame_length])\n",
    "# frames # sanity check\n",
    "\n",
    "# each dict value has to be a 1D interlaved array, as Max dict object has trouble reading 2D arrays\n",
    "# start sample is always stored at an even index and is followed by end sample\n",
    "labelled_frames = dict()\n",
    "for label, frame in zip(labels, frames):\n",
    "    if label not in labelled_frames:\n",
    "        labelled_frames[label] = []\n",
    "    labelled_frames[label].extend(frame) # use extend instead of append\n",
    "if verbose:    \n",
    "    print(len(labelled_frames[0])) # sanity check\n",
    "    print(labelled_frames[0][0], labelled_frames[0][1]) # sanity check\n",
    "\n",
    "# build a subsequence for every <step> frames\n",
    "# and a corresponding label that follows it\n",
    "x = [] # these will be features\n",
    "y = [] # these will be targets\n",
    "for i in range(0, len(labels) - maxlen, step):\n",
    "    x.append(labels[i: i + maxlen])\n",
    "    y.append(labels[i + maxlen])\n",
    "# x_ = np.array(features)\n",
    "# y_ = np.array(targets)\n",
    "# one-hot encode features and targets\n",
    "x_ = to_categorical(x, dtype =\"bool\")\n",
    "y_ = to_categorical(y, dtype =\"bool\")\n",
    "# sanity check\n",
    "if verbose:\n",
    "    print(x_.shape)\n",
    "    print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True, False],\n",
       "       [False,  True, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False,  True, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"drumloop2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 8, 4)]            0         \n",
      "                                                                 \n",
      " gru_17 (GRU)                (None, 24)                2160      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 4)                 100       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260\n",
      "Trainable params: 2,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 25ms/step - loss: 1.3863 - accuracy: 0.2007 - val_loss: 1.3377 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.2950 - accuracy: 0.6332 - val_loss: 1.2466 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.1973 - accuracy: 0.9013 - val_loss: 1.1412 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.0809 - accuracy: 1.0000 - val_loss: 1.0113 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9388 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.7755 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.6033 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.4439 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.3146 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.1577 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.1159 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 9.8663e-04 - accuracy: 1.0000 - val_loss: 9.6852e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 9.5206e-04 - accuracy: 1.0000 - val_loss: 9.3476e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 9.1900e-04 - accuracy: 1.0000 - val_loss: 9.0251e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 8.8744e-04 - accuracy: 1.0000 - val_loss: 8.7161e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 8.5722e-04 - accuracy: 1.0000 - val_loss: 8.4216e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 8.2839e-04 - accuracy: 1.0000 - val_loss: 8.1387e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 8.0067e-04 - accuracy: 1.0000 - val_loss: 7.8689e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 7.7420e-04 - accuracy: 1.0000 - val_loss: 7.6095e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 7.4886e-04 - accuracy: 1.0000 - val_loss: 7.3614e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 7.2451e-04 - accuracy: 1.0000 - val_loss: 7.1232e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 7.0117e-04 - accuracy: 1.0000 - val_loss: 6.8948e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 6.7878e-04 - accuracy: 1.0000 - val_loss: 6.6756e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 6.5731e-04 - accuracy: 1.0000 - val_loss: 6.4653e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 6.3664e-04 - accuracy: 1.0000 - val_loss: 6.2628e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 6.1685e-04 - accuracy: 1.0000 - val_loss: 6.0686e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 5.9774e-04 - accuracy: 1.0000 - val_loss: 5.8818e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 5.7942e-04 - accuracy: 1.0000 - val_loss: 5.7019e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 5.6174e-04 - accuracy: 1.0000 - val_loss: 5.5283e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 5.4480e-04 - accuracy: 1.0000 - val_loss: 5.3624e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 5.2840e-04 - accuracy: 1.0000 - val_loss: 5.2018e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 5.1263e-04 - accuracy: 1.0000 - val_loss: 5.0472e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 4.9746e-04 - accuracy: 1.0000 - val_loss: 4.8989e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 4.8282e-04 - accuracy: 1.0000 - val_loss: 4.7547e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 4.6872e-04 - accuracy: 1.0000 - val_loss: 4.6165e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 4.5513e-04 - accuracy: 1.0000 - val_loss: 4.4828e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 4.4199e-04 - accuracy: 1.0000 - val_loss: 4.3538e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 4.2932e-04 - accuracy: 1.0000 - val_loss: 4.2295e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 4.1708e-04 - accuracy: 1.0000 - val_loss: 4.1095e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 4.0526e-04 - accuracy: 1.0000 - val_loss: 3.9930e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 3.9386e-04 - accuracy: 1.0000 - val_loss: 3.8810e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# adapted from code by Lukas Biewald\n",
    "# https://github.com/lukas/ml-class/blob/master/projects/7-text-generation/char-gen.py\n",
    "\n",
    "inputs = Input(shape=(maxlen, n_labels))\n",
    "x = GRU(hidden_units)(inputs)\n",
    "outputs = Dense(n_labels, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model._name = name\n",
    "es = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', # since we are using one-hot encoded labels\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    x_,\n",
    "    y_,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=verbose,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/drumloop2\n",
      "Saved model to: models/drumloop2/drumloop2.keras\n",
      "Saved frames to: models/drumloop2/drumloop2_frames.json\n",
      "Saved config to: models/drumloop2/drumloop2_config.json\n",
      "Total epochs : 100\n",
      "0.00038809984107501805\n"
     ]
    }
   ],
   "source": [
    "path = Path(directory + \"/models/\" + name)\n",
    "print(f\"Saving model to: {path}\")\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "model_path = path / (name + \".keras\")\n",
    "model.save(model_path)\n",
    "d_path = path / (name + \"_frames.json\")\n",
    "d_path.write_text(json.dumps(labelled_frames, cls=NumpyEncoder))\n",
    "config = dict()\n",
    "config[\"filename\"] = audio_path.split('/')[-1]\n",
    "config[\"sr\"] = sr\n",
    "config[\"BPM\"] = BPM\n",
    "config[\"beat\"] = beat\n",
    "config[\"n_classes\"] = int(n_classes)\n",
    "config[\"maxlen\"] = int(maxlen)\n",
    "config[\"onset_detection\"] = False\n",
    "config[\"hop_length\"] = hop_length\n",
    "config[\"frame_length\"] = frame_length\n",
    "config[\"block_length\"] = block_length\n",
    "c_path = path / (name + \"_config.json\")    \n",
    "c_path.write_text(json.dumps(config))\n",
    "if verbose:\n",
    "    print(f\"Saved model to: {model_path}\")\n",
    "    print(f\"Saved frames to: {d_path}\")\n",
    "    print(f\"Saved config to: {c_path}\")\n",
    "print(f\"Total epochs : {len(history.history['loss'])}\")\n",
    "print(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24000,\n",
       " 36000,\n",
       " 72000,\n",
       " 84000,\n",
       " 120000,\n",
       " 132000,\n",
       " 168000,\n",
       " 180000,\n",
       " 216000,\n",
       " 228000,\n",
       " 264000,\n",
       " 276000,\n",
       " 312000,\n",
       " 324000,\n",
       " 360000,\n",
       " 372000,\n",
       " 408000,\n",
       " 420000,\n",
       " 456000,\n",
       " 468000,\n",
       " 504000,\n",
       " 516000,\n",
       " 552000,\n",
       " 564000,\n",
       " 600000,\n",
       " 612000,\n",
       " 648000,\n",
       " 660000,\n",
       " 696000,\n",
       " 708000,\n",
       " 744000,\n",
       " 756000,\n",
       " 792000,\n",
       " 804000,\n",
       " 840000,\n",
       " 852000,\n",
       " 888000,\n",
       " 900000,\n",
       " 936000,\n",
       " 948000,\n",
       " 984000,\n",
       " 996000,\n",
       " 1032000,\n",
       " 1044000,\n",
       " 1080000,\n",
       " 1092000,\n",
       " 1128000,\n",
       " 1140000,\n",
       " 1176000,\n",
       " 1188000,\n",
       " 1224000,\n",
       " 1236000,\n",
       " 1272000,\n",
       " 1284000,\n",
       " 1320000,\n",
       " 1332000,\n",
       " 1368000,\n",
       " 1380000,\n",
       " 1416000,\n",
       " 1428000,\n",
       " 1464000,\n",
       " 1476000,\n",
       " 1512000,\n",
       " 1524000,\n",
       " 1560000,\n",
       " 1572000,\n",
       " 1608000,\n",
       " 1620000,\n",
       " 1656000,\n",
       " 1668000,\n",
       " 1704000,\n",
       " 1716000,\n",
       " 1752000,\n",
       " 1764000,\n",
       " 1800000,\n",
       " 1812000,\n",
       " 1848000,\n",
       " 1860000,\n",
       " 1896000,\n",
       " 1908000,\n",
       " 1944000,\n",
       " 1956000,\n",
       " 1992000,\n",
       " 2004000,\n",
       " 2040000,\n",
       " 2052000,\n",
       " 2088000,\n",
       " 2100000,\n",
       " 2136000,\n",
       " 2148000,\n",
       " 2184000,\n",
       " 2196000,\n",
       " 2232000,\n",
       " 2244000,\n",
       " 2280000,\n",
       " 2292000,\n",
       " 2328000,\n",
       " 2340000,\n",
       " 2376000,\n",
       " 2388000,\n",
       " 2424000,\n",
       " 2436000,\n",
       " 2472000,\n",
       " 2484000,\n",
       " 2520000,\n",
       " 2532000,\n",
       " 2568000,\n",
       " 2580000,\n",
       " 2616000,\n",
       " 2628000,\n",
       " 2664000,\n",
       " 2676000,\n",
       " 2712000,\n",
       " 2724000,\n",
       " 2760000,\n",
       " 2772000,\n",
       " 2808000,\n",
       " 2820000,\n",
       " 2856000,\n",
       " 2868000,\n",
       " 2904000,\n",
       " 2916000,\n",
       " 2952000,\n",
       " 2964000,\n",
       " 3000000,\n",
       " 3012000,\n",
       " 3048000,\n",
       " 3060000,\n",
       " 3096000,\n",
       " 3108000,\n",
       " 3144000,\n",
       " 3156000,\n",
       " 3192000,\n",
       " 3204000,\n",
       " 3240000,\n",
       " 3252000,\n",
       " 3288000,\n",
       " 3300000,\n",
       " 3336000,\n",
       " 3348000,\n",
       " 3384000,\n",
       " 3396000,\n",
       " 3432000,\n",
       " 3444000,\n",
       " 3480000,\n",
       " 3492000,\n",
       " 3528000,\n",
       " 3540000,\n",
       " 3576000,\n",
       " 3588000,\n",
       " 3624000,\n",
       " 3636000,\n",
       " 3672000,\n",
       " 3684000,\n",
       " 3720000,\n",
       " 3732000,\n",
       " 3768000,\n",
       " 3780000,\n",
       " 3816000,\n",
       " 3828000,\n",
       " 3864000,\n",
       " 3876000,\n",
       " 3912000,\n",
       " 3924000,\n",
       " 3960000,\n",
       " 3972000,\n",
       " 4008000,\n",
       " 4020000,\n",
       " 4056000,\n",
       " 4068000,\n",
       " 4104000,\n",
       " 4116000,\n",
       " 4152000,\n",
       " 4164000,\n",
       " 4200000,\n",
       " 4212000,\n",
       " 4248000,\n",
       " 4260000,\n",
       " 4296000,\n",
       " 4308000,\n",
       " 4344000,\n",
       " 4356000,\n",
       " 4392000,\n",
       " 4404000,\n",
       " 4440000,\n",
       " 4452000,\n",
       " 4488000,\n",
       " 4500000,\n",
       " 4536000,\n",
       " 4548000,\n",
       " 4584000,\n",
       " 4596000,\n",
       " 4632000,\n",
       " 4644000,\n",
       " 4680000,\n",
       " 4692000,\n",
       " 4728000,\n",
       " 4740000,\n",
       " 4776000,\n",
       " 4788000,\n",
       " 4824000,\n",
       " 4836000,\n",
       " 4872000,\n",
       " 4884000,\n",
       " 4920000,\n",
       " 4932000,\n",
       " 4968000,\n",
       " 4980000,\n",
       " 5016000,\n",
       " 5028000,\n",
       " 5064000,\n",
       " 5076000,\n",
       " 5112000,\n",
       " 5124000,\n",
       " 5160000,\n",
       " 5172000,\n",
       " 5208000,\n",
       " 5220000,\n",
       " 5256000,\n",
       " 5268000,\n",
       " 5304000,\n",
       " 5316000,\n",
       " 5352000,\n",
       " 5364000,\n",
       " 5400000,\n",
       " 5412000,\n",
       " 5448000,\n",
       " 5460000,\n",
       " 5496000,\n",
       " 5508000,\n",
       " 5544000,\n",
       " 5556000,\n",
       " 5592000,\n",
       " 5604000,\n",
       " 5640000,\n",
       " 5652000,\n",
       " 5688000,\n",
       " 5700000,\n",
       " 5736000,\n",
       " 5748000,\n",
       " 5784000,\n",
       " 5796000,\n",
       " 5832000,\n",
       " 5844000,\n",
       " 5880000,\n",
       " 5892000,\n",
       " 5928000,\n",
       " 5940000,\n",
       " 5976000,\n",
       " 5988000,\n",
       " 6024000,\n",
       " 6036000,\n",
       " 6072000,\n",
       " 6084000,\n",
       " 6120000,\n",
       " 6132000,\n",
       " 6168000,\n",
       " 6180000,\n",
       " 6216000,\n",
       " 6228000,\n",
       " 6264000,\n",
       " 6276000,\n",
       " 6312000,\n",
       " 6324000,\n",
       " 6360000,\n",
       " 6372000,\n",
       " 6408000,\n",
       " 6420000,\n",
       " 6456000,\n",
       " 6468000,\n",
       " 6504000,\n",
       " 6516000,\n",
       " 6552000,\n",
       " 6564000,\n",
       " 6600000,\n",
       " 6612000,\n",
       " 6648000,\n",
       " 6660000,\n",
       " 6696000,\n",
       " 6708000,\n",
       " 6744000,\n",
       " 6756000,\n",
       " 6792000,\n",
       " 6804000,\n",
       " 6840000,\n",
       " 6852000,\n",
       " 6888000,\n",
       " 6900000,\n",
       " 6936000,\n",
       " 6948000,\n",
       " 6984000,\n",
       " 6996000,\n",
       " 7032000,\n",
       " 7044000,\n",
       " 7080000,\n",
       " 7092000,\n",
       " 7128000,\n",
       " 7140000,\n",
       " 7176000,\n",
       " 7188000,\n",
       " 7224000,\n",
       " 7236000,\n",
       " 7272000,\n",
       " 7284000,\n",
       " 7320000,\n",
       " 7332000,\n",
       " 7368000,\n",
       " 7380000,\n",
       " 7416000,\n",
       " 7428000,\n",
       " 7464000,\n",
       " 7476000,\n",
       " 7512000,\n",
       " 7524000,\n",
       " 7560000,\n",
       " 7572000,\n",
       " 7608000,\n",
       " 7620000,\n",
       " 7656000,\n",
       " 7668000,\n",
       " 7704000,\n",
       " 7716000,\n",
       " 7752000,\n",
       " 7764000,\n",
       " 7800000,\n",
       " 7812000,\n",
       " 7848000,\n",
       " 7860000,\n",
       " 7896000,\n",
       " 7908000,\n",
       " 7944000,\n",
       " 7956000,\n",
       " 7992000,\n",
       " 8004000,\n",
       " 8040000,\n",
       " 8052000,\n",
       " 8088000,\n",
       " 8100000,\n",
       " 8136000,\n",
       " 8148000,\n",
       " 8184000,\n",
       " 8196000,\n",
       " 8232000,\n",
       " 8244000,\n",
       " 8280000,\n",
       " 8292000,\n",
       " 8328000,\n",
       " 8340000,\n",
       " 8376000,\n",
       " 8388000,\n",
       " 8424000,\n",
       " 8436000,\n",
       " 8472000,\n",
       " 8484000,\n",
       " 8520000,\n",
       " 8532000,\n",
       " 8568000,\n",
       " 8580000,\n",
       " 8616000,\n",
       " 8628000,\n",
       " 8664000,\n",
       " 8676000,\n",
       " 8712000,\n",
       " 8724000,\n",
       " 8760000,\n",
       " 8772000,\n",
       " 8808000,\n",
       " 8820000,\n",
       " 8856000,\n",
       " 8868000,\n",
       " 8904000,\n",
       " 8916000,\n",
       " 8952000,\n",
       " 8964000,\n",
       " 9000000,\n",
       " 9012000,\n",
       " 9048000,\n",
       " 9060000,\n",
       " 9096000,\n",
       " 9108000,\n",
       " 9144000,\n",
       " 9156000,\n",
       " 9192000,\n",
       " 9204000]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
